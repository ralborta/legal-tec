import { legalDb } from "./db.js";
import { getDocumentBuffer } from "./storage.js";
import { ocrAgent } from "./agents/ocr.js";
import { translatorAgent } from "./agents/translator.js";
import { classifierAgent } from "./agents/classifier.js";
import { runDistributionAnalyzer } from "./agents/analyzerDistribution.js";
import { generateReport } from "./agents/report.js";
import { acquireAnalysisSlot } from "./concurrency-limit.js";

// Función para análisis conjunto de múltiples documentos
export async function runFullAnalysisMany(documentIds: string[], userInstructions?: string | null) {
  const startTime = Date.now();
  const MAX_PIPELINE_TIME = 300000; // 5 minutos para múltiples documentos
  const trimmedInstructions = userInstructions?.trim() || null;
  
  // Adquirir slot de análisis
  const releaseSlot = await acquireAnalysisSlot();
  console.log(`[PIPELINE-MANY] Slot adquirido para análisis conjunto de ${documentIds.length} documentos`);
  
  const pipelineTimeout = setTimeout(() => {
    console.error(`[PIPELINE-MANY] TIMEOUT: Analysis exceeded ${MAX_PIPELINE_TIME}ms for ${documentIds.length} documents`);
    releaseSlot();
    throw new Error(`Pipeline timeout: analysis took more than ${MAX_PIPELINE_TIME / 1000}s`);
  }, MAX_PIPELINE_TIME);
  
  try {
    // El primer documento será el "principal" donde guardaremos el análisis conjunto
    const primaryDocumentId = documentIds[0];
    const otherDocumentIds = documentIds.slice(1);
    
    console.log(`[PIPELINE-MANY] Starting CONJOINT analysis for ${documentIds.length} documents`);
    console.log(`[PIPELINE-MANY] Primary document: ${primaryDocumentId}`);
    console.log(`[PIPELINE-MANY] Other documents: ${otherDocumentIds.join(", ")}`);
    
    await updateAnalysisStatus(primaryDocumentId, "ocr", 10);
    
    // 1. Extraer texto de TODOS los documentos
    const allTexts: Array<{ documentId: string; filename: string; text: string }> = [];
    
    for (const docId of documentIds) {
      const doc = await legalDb.getDocument(docId);
      if (!doc) {
        throw new Error(`Document ${docId} not found`);
      }
      
      const fileBuffer = await getDocumentBuffer(docId);
      if (!fileBuffer) {
        throw new Error(`Could not read file for document ${docId}`);
      }
      
      const text = await ocrAgent({
        buffer: fileBuffer,
        mimeType: doc.mime_type,
        filename: doc.filename,
      });
      
      allTexts.push({
        documentId: docId,
        filename: doc.filename,
        text: text,
      });
      
      console.log(`[PIPELINE-MANY] ✅ Extracted ${text.length} chars from ${doc.filename}`);
    }
    
    // 2. Combinar todos los textos con separadores claros
    const combinedText = allTexts.map((item, index) => {
      return `\n\n═══════════════════════════════════════════════════════════════════════════════
DOCUMENTO ${index + 1} de ${allTexts.length}: ${item.filename}
Document ID: ${item.documentId}
═══════════════════════════════════════════════════════════════════════════════\n${item.text}`;
    }).join("\n\n");
    
    console.log(`[PIPELINE-MANY] Combined text length: ${combinedText.length} characters`);
    await updateAnalysisStatus(primaryDocumentId, "translating", 25);
    
    // 3. Traducción y estructuración del texto combinado
    const translated = await translatorAgent(combinedText);
    console.log(`[PIPELINE-MANY] Translation completed, ${translated.length} clauses from all documents`);
    await updateAnalysisStatus(primaryDocumentId, "classifying", 40);
    
    // 4. Clasificación (del conjunto)
    const { type } = await classifierAgent(translated);
    console.log(`[PIPELINE-MANY] Classification: ${type}`);
    await updateAnalysisStatus(primaryDocumentId, "analyzing", 60);
    
    // 5. Análisis específico según tipo
    let checklist: any = null;
    if (type === "distribution_contract") {
      checklist = await runDistributionAnalyzer(translated);
      console.log(`[PIPELINE-MANY] Distribution analysis completed`);
    } else {
      checklist = { type, note: "No specific analyzer implemented yet" };
    }
    await updateAnalysisStatus(primaryDocumentId, "generating_report", 80);
    
    // 6. Generar reporte conjunto con instrucciones especiales
    const manyInstructions = trimmedInstructions 
      ? `${trimmedInstructions}\n\nIMPORTANTE: Este análisis incluye ${documentIds.length} documentos relacionados. Analiza el CONJUNTO de todos los documentos, sus relaciones, consistencias, contradicciones, y cómo se complementan entre sí. Identifica si forman parte de una transacción o proceso legal conjunto.`
      : `IMPORTANTE: Este análisis incluye ${documentIds.length} documentos relacionados. Analiza el CONJUNTO de todos los documentos, sus relaciones, consistencias, contradicciones, y cómo se complementan entre sí. Identifica si forman parte de una transacción o proceso legal conjunto.`;
    
    const report = await generateReport({
      original: combinedText,
      translated,
      type,
      checklist,
      userInstructions: manyInstructions,
    });
    console.log(`[PIPELINE-MANY] Report generated for ${documentIds.length} documents`);
    await updateAnalysisStatus(primaryDocumentId, "saving", 90);
    
    // 7. Guardar análisis en el documento principal
    await legalDb.upsertAnalysis({
      documentId: primaryDocumentId,
      type,
      original: { text: combinedText, documents: allTexts.map(t => ({ id: t.documentId, filename: t.filename })) },
      translated,
      checklist,
      report,
      userInstructions: trimmedInstructions,
    });
    
    // Guardar referencia en los otros documentos también
    for (const docId of otherDocumentIds) {
      await legalDb.upsertAnalysis({
        documentId: docId,
        type,
        original: { text: "", isPartOfConjointAnalysis: true, primaryDocumentId },
        translated: [],
        checklist: null,
        report: null,
        userInstructions: trimmedInstructions,
      });
    }
    
    const duration = ((Date.now() - startTime) / 1000).toFixed(1);
    console.log(`[PIPELINE-MANY] Conjoint analysis completed for ${documentIds.length} documents in ${duration}s`);
    await updateAnalysisStatus(primaryDocumentId, "completed", 100);
    clearTimeout(pipelineTimeout);
    releaseSlot();
  } catch (error) {
    clearTimeout(pipelineTimeout);
    releaseSlot();
    const duration = ((Date.now() - startTime) / 1000).toFixed(1);
    console.error(`[PIPELINE-MANY] ERROR after ${duration}s:`, error);
    await updateAnalysisStatus(documentIds[0], "error", 0);
    await legalDb.setAnalysisError(
      documentIds[0],
      error instanceof Error ? error.message : "Error desconocido"
    );
    throw error;
  }
}

// Función helper para actualizar estado del análisis
async function updateAnalysisStatus(documentId: string, status: string, progress: number) {
  try {
    await legalDb.updateAnalysisStatus(documentId, status, progress);
  } catch (error) {
    console.warn(`[PIPELINE] No se pudo actualizar estado: ${error}`);
  }
}

export async function runFullAnalysis(documentId: string, userInstructions?: string | null) {
  const startTime = Date.now();
  const MAX_PIPELINE_TIME = 180000; // 3 minutos máximo para todo el pipeline
  const trimmedInstructions = userInstructions?.trim() || null;
  
  // Adquirir slot de análisis (limita concurrencia)
  const releaseSlot = await acquireAnalysisSlot();
  console.log(`[PIPELINE] Slot adquirido para análisis ${documentId}`);
  
  // Timeout global para todo el pipeline
  const pipelineTimeout = setTimeout(() => {
    console.error(`[PIPELINE] TIMEOUT: Analysis exceeded ${MAX_PIPELINE_TIME}ms for document ${documentId}`);
    releaseSlot(); // Liberar slot en caso de timeout
    throw new Error(`Pipeline timeout: analysis took more than ${MAX_PIPELINE_TIME / 1000}s`);
  }, MAX_PIPELINE_TIME);
  
  try {
    const doc = await legalDb.getDocument(documentId);
    if (!doc) {
      throw new Error("Document not found");
    }

    console.log(`[PIPELINE] Starting FULL analysis for document ${documentId}`);
    await updateAnalysisStatus(documentId, "ocr", 10);

    // 1. OCR / Extraer texto
    const fileBuffer = await getDocumentBuffer(documentId);
    if (!fileBuffer) {
      // Si no se puede leer el archivo, intentar regenerar usando datos existentes
      console.warn(`[PIPELINE] ⚠️ No se pudo leer el archivo, intentando regenerar usando datos existentes...`);
      const existingAnalysis = await legalDb.getAnalysis(documentId);
      if (existingAnalysis && existingAnalysis.original && existingAnalysis.translated) {
        console.log(`[PIPELINE] ✅ Análisis previo encontrado, regenerando solo el reporte...`);
        // No borrar el análisis, solo regenerar el reporte
        return await regenerateReportOnly(documentId, trimmedInstructions, existingAnalysis);
      } else {
        throw new Error("Could not read document file and no previous analysis available");
      }
    }

    // Si hay un análisis previo y tenemos el archivo, limpiarlo para regenerar TODO desde cero
    const existingAnalysis = await legalDb.getAnalysis(documentId);
    if (existingAnalysis) {
      console.log(`[PIPELINE] ⚠️ Análisis previo encontrado para ${documentId}, limpiando para regeneración completa...`);
      await legalDb.deleteAnalysis(documentId);
      console.log(`[PIPELINE] ✅ Análisis previo eliminado, iniciando pipeline completo desde cero`);
    }

  const originalText = await ocrAgent({
    buffer: fileBuffer,
    mimeType: doc.mime_type,
    filename: doc.filename,
  });

  console.log(`[PIPELINE] OCR completed, extracted ${originalText.length} characters`);
  await updateAnalysisStatus(documentId, "translating", 25);

  // 2. Traducción y estructuración
  const translated = await translatorAgent(originalText);
  console.log(`[PIPELINE] Translation completed, ${translated.length} clauses`);
  await updateAnalysisStatus(documentId, "classifying", 40);

  // 3. Clasificación genérica
  const { type } = await classifierAgent(translated);
  console.log(`[PIPELINE] Classification: ${type}`);
  await updateAnalysisStatus(documentId, "analyzing", 60);

  // 4. Router según tipo (por ahora, BASEUS / distribución)
  let checklist: any = null;
  if (type === "distribution_contract") {
    checklist = await runDistributionAnalyzer(translated);
    console.log(`[PIPELINE] Distribution analysis completed`);
  } else {
    checklist = { type, note: "No specific analyzer implemented yet" };
  }
  await updateAnalysisStatus(documentId, "generating_report", 80);

  // 5. Generar reporte
  const report = await generateReport({
    original: originalText,
    translated,
    type,
    checklist,
    userInstructions: trimmedInstructions || undefined,
  });
  console.log(`[PIPELINE] Report generated`);
  await updateAnalysisStatus(documentId, "saving", 90);

  // 6. Guardar análisis
  await legalDb.upsertAnalysis({
    documentId,
    type,
    original: { text: originalText },
    translated,
    checklist,
    report,
    userInstructions: trimmedInstructions,
  });

    const duration = ((Date.now() - startTime) / 1000).toFixed(1);
    console.log(`[PIPELINE] Analysis completed for document ${documentId} in ${duration}s`);
    await updateAnalysisStatus(documentId, "completed", 100);
    clearTimeout(pipelineTimeout);
    releaseSlot(); // Liberar slot al completar
  } catch (error) {
    clearTimeout(pipelineTimeout);
    releaseSlot(); // Liberar slot en caso de error
    const duration = ((Date.now() - startTime) / 1000).toFixed(1);
    console.error(`[PIPELINE] ERROR after ${duration}s:`, error);
    await updateAnalysisStatus(documentId, "error", 0);
    await legalDb.setAnalysisError(
      documentId,
      error instanceof Error ? error.message : "Error desconocido"
    );
    throw error;
  }
}

// Función para regenerar solo el reporte usando datos existentes (sin archivo)
export async function regenerateReportOnly(
  documentId: string,
  userInstructions?: string | null,
  existingAnalysis?: any
) {
  try {
    console.log(`[REGENERATE-REPORT] ========================================`);
    console.log(`[REGENERATE-REPORT] Iniciando regeneración para documento ${documentId}`);
    console.log(`[REGENERATE-REPORT] Instrucciones del usuario: ${userInstructions ? `SÍ (${userInstructions.length} chars)` : 'NO'}`);
    
    // Actualizar estado inicial
    await updateAnalysisStatus(documentId, "generating_report", 10);
    console.log(`[REGENERATE-REPORT] ✅ Estado actualizado a 'generating_report' (10%)`);
    
    // Si no se pasó el análisis, obtenerlo de la DB
    let analysis = existingAnalysis;
    if (!analysis) {
      console.log(`[REGENERATE-REPORT] Obteniendo análisis de la DB...`);
      analysis = await legalDb.getAnalysis(documentId);
      if (!analysis) {
        throw new Error("No hay análisis previo disponible para regenerar");
      }
      console.log(`[REGENERATE-REPORT] ✅ Análisis obtenido de la DB`);
    } else {
      console.log(`[REGENERATE-REPORT] ✅ Usando análisis pasado como parámetro`);
    }
    
    // Parsear los datos existentes
    console.log(`[REGENERATE-REPORT] Parseando datos existentes...`);
    const original = typeof analysis.original === 'string' 
      ? JSON.parse(analysis.original) 
      : analysis.original;
    const translated = typeof analysis.translated === 'string'
      ? JSON.parse(analysis.translated)
      : analysis.translated;
    const checklist = typeof analysis.checklist === 'string'
      ? JSON.parse(analysis.checklist)
      : analysis.checklist;
    console.log(`[REGENERATE-REPORT] ✅ Datos parseados: original=${typeof original}, translated=${Array.isArray(translated) ? translated.length + ' cláusulas' : typeof translated}, checklist=${typeof checklist}`);
    
    // Extraer texto original (puede estar en formato objeto o string)
    let originalText: string;
    if (typeof original === 'string') {
      originalText = original;
    } else if (original && typeof original === 'object' && original.text) {
      originalText = original.text;
    } else {
      originalText = JSON.stringify(original);
    }
    console.log(`[REGENERATE-REPORT] ✅ Texto original extraído: ${originalText.length} caracteres`);
    
    // Actualizar estado - asegurar que el documento existe en la DB
    console.log(`[REGENERATE-REPORT] Verificando que el documento existe en la DB...`);
    const doc = await legalDb.getDocument(documentId);
    if (!doc) {
      throw new Error("Document not found in database");
    }
    console.log(`[REGENERATE-REPORT] ✅ Documento verificado: ${doc.filename}`);
    
    await updateAnalysisStatus(documentId, "generating_report", 50);
    console.log(`[REGENERATE-REPORT] ✅ Estado actualizado a 'generating_report' (50%)`);
    
    // Generar nuevo reporte con las instrucciones del usuario
    console.log(`[REGENERATE-REPORT] Generando nuevo reporte con gpt-4o...`);
    await updateAnalysisStatus(documentId, "generating_report", 60);
    const report = await generateReport({
      original: originalText,
      translated,
      type: analysis.type || "unknown",
      checklist,
      userInstructions: userInstructions || undefined,
    });
    console.log(`[REGENERATE-REPORT] ✅ Reporte generado exitosamente`);
    
    // Guardar el nuevo reporte (manteniendo original, translated, checklist)
    console.log(`[REGENERATE-REPORT] Guardando análisis en la DB...`);
    await updateAnalysisStatus(documentId, "saving", 90);
    await legalDb.upsertAnalysis({
      documentId,
      type: analysis.type || "unknown",
      original,
      translated,
      checklist,
      report,
      userInstructions: userInstructions || undefined,
    });
    console.log(`[REGENERATE-REPORT] ✅ Análisis guardado en la DB`);
    
    await updateAnalysisStatus(documentId, "completed", 100);
    console.log(`[REGENERATE-REPORT] ✅ Reporte regenerado exitosamente para documento ${documentId}`);
    console.log(`[REGENERATE-REPORT] ========================================`);
  } catch (error: any) {
    console.error(`[REGENERATE-REPORT] ❌ Error regenerando reporte:`, error);
    await updateAnalysisStatus(documentId, "error", 0);
    throw error;
  }
}
